{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf340
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \\section\{Fundamental Protocols\}\
We have covered two important metrics when it comes to deliver bytes from a client to the server and vice versa. To understand why these metrics can have great impact on the overall web performance, we take a closer look on the fundamental internet protocols involved when requesting a web page. \
\
\\subsection\{HTTP (Hypertext Transfer Protocol)\}\
HTTP is part of layer 7 in the OSI model and comes into play when the browser talks to the server about it's capabilities and requirements whereas the server tells the browser how to treat content appropriately. As soon as address information and an underlying TCP connection is available, the browser sends an HTTP request using this connection by specifying the method and relevant information packed within a so called HTTP header and body. The basic request methods supported by every browser are GET and POST whereby GET allows to send custom parameters (data concerning the purpose of the application) within the header and POST within it's body. Furthermore the browser can add different properties to tell which version it supports, whether compression and caching can be used or TCP connections should be kept open. Adapting these properties in a web server's configuration  can help  to optimize performance remarkably \\cite\{Chang_2008\}.\
\
\\subsection\{TCP (Transmission Control Protocol)\}\
TCP is the mostly used transport protocol and the basis for nearly all of the HTTP traffic delivered on the Internet. Due to it's many features it supports out of the box it's a rich protocol as well as an essential performance factor. Although TCP is pretty low-level and web developers most likely won't face it directly, several configurations done in the application layer, in essence in HTTP, influence the performance of TCP and the underlying network. To understand why TCP is very sensitive regarding latency we have to take a closer look on the basic techniques behind it. \
\
TCP connections start with a three-way handshake between client and server because they must agree on connection specific variables. First the sender sends a SYN packet which is acknowledged by the receiver with a SYN ACK and only directly after the ACK packet from the client application data can be sent. This procedure obviously requires a full roundtrip between client and server before any data is sent. In it's simplest and initial form every HTTP request opens a new TCP connection which introduces time loss where no application data can be transferred. \
\
Since TCP promises that packets will be delivered in-order, in-time and reliable it contains special algorithms, called flow control and congestion control respectively avoidance to handle bandwidth differences and network condition varieties appropriately. TCP regulates the speed at which packets are transferred according to the capabilities of sender and receiver. After an ACK each side advertises it's new receiving window indicating how many bytes it is able to receive at once by not being overwhelmed from the other side. With a mechanism called "Slow Start" TCP prevents both sides from overwhelming the underlying network. It therefore introduces a conservative congestion window which grows exponentially after each ACK packet to increase the amount of bytes over time until first packets get lost. Then the congestion avoidance intervenes and resets the window to a smaller size. The minimum between the receiving window and the congestion window indicates the amount of packet segments to be sent in one turn. \
Let's examine an example of how this slow start can look like in practice if we want to transfer 64KB with an initial congestion window of 4 segments between New York and Sydney (RTT = 160ms).\
%% sind das ihre messungen? falls nicht, schon hier quelle angeben: (example taken from \\cite\{??\})\
%% und in jedem fall gehe ich davon aus, dass die formulierungen von ihnen selbst stammen und keine w\'c3\'b6rtlichen zitate sind, das gilt \'c3\'8cbrigens f\'c3\'8cr die ganze arbeit!\
\
$$\\frac\{65535 bytes\}\{1460 bytes\} = ~45 segments$$\
$$160ms * \\log_2 (\\frac\{45\}\{4\}) = ~559ms$$\
\
As we can see from the results it takes about 560ms to reach the throughput of 64KB. This is more than three roundtrips between New York and Sydney plus the time required for the three-way handshake the resulting latency is quite a lot. TCP internally negotiates and adjusts the size of the window according to available bandwidth, RTT and network conditions to optimize throughput and prevent gaps where one side has to wait for an ACK of unacknowledged data before it can send new data. All in all we can see that having an eye on the internals of TCP can make a big difference as we have seen \\cite\{Grigorik_2013\}.\
}